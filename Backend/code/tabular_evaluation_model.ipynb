{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UArTTWBaSI_i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from scipy.stats import uniform, randint\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1DObLtBkRkpV"
      },
      "outputs": [],
      "source": [
        "# Importing data\n",
        "df = pd.read_csv(\"../data/finaldataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z_3pGgngX6uk"
      },
      "outputs": [],
      "source": [
        "#same preprocessing steps as Darts models\n",
        "\n",
        "#Remove countries with very few observations\n",
        "df = df[df[\"country_d\"] != \"Taiwan\"]\n",
        "df = df[df[\"country_d\"] != \"North Korea\"]\n",
        "df = df[df[\"country_d\"] != \"Liechtenstein\"]\n",
        "df = df[df[\"country_d\"] != \"Monaco\"]\n",
        "df = df[df[\"country_d\"] != \"Botswana\"]\n",
        "df = df[df[\"country_d\"] != \"Lesotho\"]\n",
        "df = df[df[\"country_d\"] != \"Luxembourg\"]\n",
        "df = df[df[\"country_d\"] != \"Yugoslavia\"]\n",
        "df = df[df[\"country_d\"] != \"Sao Tome and Principe\"]\n",
        "df = df[df[\"country_d\"] != \"Iraq\"]\n",
        "df = df[df[\"country_d\"] != \"Sudan\"]\n",
        "df = df[df[\"country_d\"] != \"Equatorial Guinea\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uonpyr7GYSkX"
      },
      "outputs": [],
      "source": [
        "#Obtaining bilateral trade value:\n",
        "#Use Singapore-reported export value by default, if NaN, use trade partner reported import value\n",
        "#combined trade series ensure broader coverage\n",
        "#method adapted from CEPII Trade and Production database (TradeProd)\n",
        "#https://www.cepii.fr/DATA_DOWNLOAD/tradeprod/V202401/CEPII_TradeProd_V202401.pdf\n",
        "\n",
        "df[\"all_exports_new\"] = np.where(\n",
        "    df[\"tradeflow_comtrade_o\"].notna(),\n",
        "    df[\"tradeflow_comtrade_o\"],\n",
        "    np.where(\n",
        "        df[\"tradeflow_comtrade_d\"].notna(),\n",
        "        df[\"tradeflow_comtrade_d\"],\n",
        "        np.nan\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"log_all_exports_new\"] = np.log1p(df[\"all_exports_new\"])\n",
        "df[\"log_gdpcap_d\"] = np.log1p(df[\"gdpcap_d\"])\n",
        "df[\"log_pop_d\"] = np.log1p(df[\"pop_d\"])\n",
        "df[\"log_distcap\"] = np.log1p(df[\"distcap\"])"
      ],
      "metadata": {
        "id": "g8ykd2eFmaOn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xJi2EmjURACI"
      },
      "outputs": [],
      "source": [
        "# Sorting by (country_d, year)\n",
        "df_2 = df.sort_values(by=['country_d', 'year'])\n",
        "\n",
        "# Set lag variables\n",
        "df_2['lag_log_pop_d'] = df_2.groupby('country_d')['log_pop_d'].shift(1)\n",
        "df_2['lag_log_gdpcap_d'] = df_2.groupby('country_d')['log_gdpcap_d'].shift(1)\n",
        "df_2['lag_geodistance'] = df_2.groupby('country_d')['geodistance'].shift(1)\n",
        "\n",
        "df_2 = df_2[df_2.groupby('country_d')['year'].diff() == 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "n-4__YZwRYOo",
        "outputId": "05289bec-e1c4-47c3-8e03-1ffe745c1d85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lag_geodistance    -0.139940\n",
              "log_distcap        -0.414728\n",
              "lag_log_gdpcap_d    0.460146\n",
              "lag_log_pop_d       0.487271\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>lag_geodistance</th>\n",
              "      <td>-0.139940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>log_distcap</th>\n",
              "      <td>-0.414728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag_log_gdpcap_d</th>\n",
              "      <td>0.460146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lag_log_pop_d</th>\n",
              "      <td>0.487271</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_2[['lag_geodistance', 'log_distcap', 'lag_log_gdpcap_d', 'lag_log_pop_d']].corrwith(df_2['log_all_exports_new'])\n",
        "\n",
        "# signs of each variable's correlation with target variable are expected"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_years = pd.date_range(start=\"1989-12-31\", end=\"2020-12-31\", freq=\"YE\")\n",
        "full_years_df = pd.DataFrame({\"year\": full_years})\n",
        "\n",
        "country_frames = []\n",
        "\n",
        "# Loop through each country\n",
        "for country in df_2['country_d'].unique():\n",
        "\n",
        "    # Filter for current country\n",
        "    df_country = df_2[df_2['country_d'] == country].copy()\n",
        "\n",
        "    # Ensure all years are present\n",
        "    full_years_country = full_years_df.copy()\n",
        "    full_years_country['country_d'] = country\n",
        "\n",
        "    df_country[\"year\"] = pd.to_datetime(df_country[\"year\"], format=\"%Y\") + pd.offsets.YearEnd(0)\n",
        "\n",
        "    df_country = pd.merge(full_years_country, df_country, on=[\"year\", \"country_d\"], how=\"left\")\n",
        "\n",
        "    # Drop duplicate years (in case of prior merge artifacts)\n",
        "    df_country = df_country.drop_duplicates(subset=[\"year\"], keep=\"first\")\n",
        "\n",
        "    vars_to_fill = ['log_all_exports_new', 'lag_geodistance', 'log_distcap', 'lag_log_gdpcap_d', 'lag_log_pop_d']\n",
        "\n",
        "    before_2009 = df_country[\"year\"] <= pd.Timestamp(\"2008-12-31\")\n",
        "    df_before_2009 = df_country[before_2009].copy()\n",
        "\n",
        "    # Interpolate pre-2009\n",
        "    for var in vars_to_fill:\n",
        "        df_country.loc[before_2009, var] = (\n",
        "            df_country.loc[before_2009, var]\n",
        "            .interpolate(method=\"linear\", limit_direction=\"both\")\n",
        "        )\n",
        "\n",
        "    # Handle 2009 special case\n",
        "    mask_2009 = df_country[\"year\"] == pd.Timestamp(\"2009-12-31\")\n",
        "    for var in vars_to_fill:\n",
        "        if df_country.loc[mask_2009, var].isna().any():\n",
        "            last_val = df_before_2009[var].dropna().iloc[-1]\n",
        "            df_country.loc[mask_2009, var] = last_val\n",
        "\n",
        "\n",
        "    # Forward-fill for 2009 onwards\n",
        "    from_2009 = df_country[\"year\"] >= pd.Timestamp(\"2009-12-31\")\n",
        "    df_country.loc[from_2009, vars_to_fill] = (\n",
        "        df_country.loc[from_2009, vars_to_fill].ffill()\n",
        "    )\n",
        "\n",
        "    country_frames.append(df_country)\n",
        "\n",
        "\n",
        "df_2 = pd.concat(country_frames).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "yEbdBKbwB7J1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#expanding window cv function\n",
        "\n",
        "def expanding_window_cv_countrywise(model, X, y, countries, year_col='year', min_year=1989, max_year=2020, min_train_years=20):\n",
        "    min_year = pd.Timestamp(f\"{min_year}-12-31\")\n",
        "    max_year = pd.Timestamp(f\"{max_year}-12-31\")\n",
        "\n",
        "    country_metrics = []\n",
        "    all_predictions = []\n",
        "\n",
        "    for country in countries:\n",
        "        # Filter by country\n",
        "        country_mask = X['country_d'] == country\n",
        "        X_country = X.loc[country_mask].copy()\n",
        "        y_country = y.loc[country_mask].copy()\n",
        "\n",
        "        # Filter by years\n",
        "        year_mask = (X_country[year_col] >= min_year) & (X_country[year_col] <= max_year)\n",
        "        X_country = X_country.loc[year_mask]\n",
        "        y_country = y_country.loc[year_mask]\n",
        "\n",
        "        unique_years = sorted(X_country[year_col].unique())\n",
        "        if len(unique_years) <= min_train_years:\n",
        "            continue\n",
        "\n",
        "        predictions = pd.Series(index=y_country.index, dtype=float)\n",
        "        y_true_total = []\n",
        "        y_pred_total = []\n",
        "\n",
        "        for i in range(min_train_years, len(unique_years) - 1):\n",
        "            train_years = unique_years[:i]\n",
        "            test_year = unique_years[i]\n",
        "\n",
        "            train_mask = X_country[year_col].isin(train_years)\n",
        "            test_mask = X_country[year_col] == test_year\n",
        "\n",
        "            X_train = X_country.loc[train_mask].drop(columns=[year_col, 'country_d'])\n",
        "            X_test = X_country.loc[test_mask].drop(columns=[year_col, 'country_d'])\n",
        "            y_train = y_country.loc[train_mask]\n",
        "            y_test = y_country.loc[test_mask]\n",
        "\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            # Store actual and predicted\n",
        "            y_true_total.extend(y_test.values.flatten())\n",
        "            y_pred_total.extend(y_pred.flatten())\n",
        "\n",
        "            predictions.loc[y_test.index] = y_pred.flatten()\n",
        "\n",
        "        if y_true_total:\n",
        "            # Compute single metric per country from all y_true vs y_pred\n",
        "            mse = mean_squared_error(y_true_total, y_pred_total)\n",
        "            rmse = np.sqrt(mse)\n",
        "            mae = mean_absolute_error(y_true_total, y_pred_total)\n",
        "            mape = mean_absolute_percentage_error(y_true_total, y_pred_total)\n",
        "\n",
        "            country_metrics.append({\n",
        "                'country': country,\n",
        "                'mse': mse,\n",
        "                'rmse': rmse,\n",
        "                'mae': mae,\n",
        "                'mape': mape,\n",
        "                'n_preds': len(y_true_total)\n",
        "            })\n",
        "\n",
        "            all_predictions.append(predictions)\n",
        "\n",
        "    # Combine all predictions\n",
        "    final_predictions = pd.concat(all_predictions).sort_index()\n",
        "\n",
        "    # Average metrics across countries\n",
        "    if country_metrics:\n",
        "        avg_metrics = {\n",
        "            'avg_mse': np.mean([m['mse'] for m in country_metrics]),\n",
        "            'avg_rmse': np.mean([m['rmse'] for m in country_metrics]),\n",
        "            'avg_mae': np.mean([m['mae'] for m in country_metrics]),\n",
        "            'avg_mape': np.mean([m['mape'] for m in country_metrics]),\n",
        "            'countries': len(country_metrics)\n",
        "        }\n",
        "    else:\n",
        "        avg_metrics = {}\n",
        "\n",
        "    return final_predictions, avg_metrics, country_metrics\n"
      ],
      "metadata": {
        "id": "ysJgfnuvfUec"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgboostX = df_2[['country_d', 'log_distcap', 'lag_geodistance', 'lag_log_pop_d', 'lag_log_gdpcap_d', 'year']].copy()\n",
        "xgboostY = df_2[['log_all_exports_new']]\n",
        "\n",
        "# Run country-wise cross-validation\n",
        "countries = df_2['country_d'].unique()\n",
        "\n",
        "xgboostModel = xgb.XGBRegressor(\n",
        "    n_estimators = 100,\n",
        "    max_depth = 4,\n",
        "    learning_rate = 0.05,\n",
        "    subsample = 0.8,\n",
        "    colsample_bytree = 0.8,\n",
        "    random_state = 222\n",
        ")\n",
        "\n",
        "xgboostPredictions, xgboostAvgMetrics, xgboostCountryMetrics = expanding_window_cv_countrywise(\n",
        "    xgboostModel, xgboostX, xgboostY, countries\n",
        ")\n",
        "\n",
        "# Print summary metrics\n",
        "print(\"Average Metrics Across Countries:\")\n",
        "print(xgboostAvgMetrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFs_4RUbjn3G",
        "outputId": "8bc5a4c9-b311-47c2-dc51-04d0fad3e7b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metrics Across Countries:\n",
            "{'avg_mse': np.float64(0.576150598813245), 'avg_rmse': np.float64(0.613385048135207), 'avg_mae': np.float64(0.4792252223754813), 'avg_mape': np.float64(0.02942200276850364), 'countries': 161}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rfX = df_2[['country_d', 'log_distcap', 'lag_geodistance', 'lag_log_pop_d', 'lag_log_gdpcap_d', 'year']].copy()\n",
        "rfY = df_2[['log_all_exports_new']]\n",
        "\n",
        "# Run country-wise cross-validation\n",
        "countries = df_2['country_d'].unique()\n",
        "\n",
        "rfModel = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=222,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rfPredictions, rfAvgMetrics, rfCountryMetrics = expanding_window_cv_countrywise(\n",
        "    rfModel, rfX, rfY, countries\n",
        ")\n",
        "\n",
        "# Print summary metrics\n",
        "print(\"Average Metrics Across Countries:\")\n",
        "print(rfAvgMetrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3HwT7WNPiEj",
        "outputId": "fc0a5e98-6811-4062-9303-0f420c37f8d7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metrics Across Countries:\n",
            "{'avg_mse': np.float64(0.591814404321084), 'avg_rmse': np.float64(0.6157920805512621), 'avg_mae': np.float64(0.4863432130973088), 'avg_mape': np.float64(0.029994500920421763), 'countries': 161}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}